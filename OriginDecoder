{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12287144,"sourceType":"datasetVersion","datasetId":7743669},{"sourceId":12315409,"sourceType":"datasetVersion","datasetId":7762636}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Kaggle Environment Setup - Clean installation with isolated dependencies\n!pip install --force-reinstall numpy==1.26.4\n!pip install transformers==4.41.0 torch==2.1.2 sentencepiece phonemizer epitran spacy==3.7.4 sacrebleu importlib_metadata==7.1.0\n!python -m spacy download -q en_core_web_sm-3.7.0 --direct\n\n# Clean up potential conflicts\n!pip uninstall -y torchao accelerate\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T07:21:25.539139Z","iopub.execute_input":"2025-12-30T07:21:25.539374Z","iopub.status.idle":"2025-12-30T07:25:14.292243Z","shell.execute_reply.started":"2025-12-30T07:21:25.539353Z","shell.execute_reply":"2025-12-30T07:25:14.290661Z"}},"outputs":[{"name":"stdout","text":"Collecting numpy==1.26.4\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndatasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nopencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.26.4\nCollecting transformers==4.41.0\n  Downloading transformers-4.41.0-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting torch==2.1.2\n  Downloading torch-2.1.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\nCollecting phonemizer\n  Downloading phonemizer-3.3.0-py3-none-any.whl.metadata (48 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting epitran\n  Downloading epitran-1.34.0-py3-none-any.whl.metadata (36 kB)\nCollecting spacy==3.7.4\n  Downloading spacy-3.7.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\nCollecting sacrebleu\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting importlib_metadata==7.1.0\n  Downloading importlib_metadata-7.1.0-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.0) (3.20.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.0) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.0) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.0) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.0) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.0) (2.32.5)\nCollecting tokenizers<0.20,>=0.19 (from transformers==4.41.0)\n  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.0) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.0) (4.67.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (4.15.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2)\n  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.1.0 (from torch==2.1.2)\n  Downloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (1.0.13)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (3.0.10)\nCollecting thinc<8.3.0,>=8.2.2 (from spacy==3.7.4)\n  Downloading thinc-8.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (2.0.10)\nCollecting weasel<0.4.0,>=0.1.0 (from spacy==3.7.4)\n  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\nCollecting typer<0.10.0,>=0.3.0 (from spacy==3.7.4)\n  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\nCollecting smart-open<7.0.0,>=5.2.1 (from spacy==3.7.4)\n  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (2.12.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (75.2.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.4) (3.5.0)\nRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata==7.1.0) (3.23.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2) (12.5.82)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from phonemizer) (1.5.2)\nCollecting segments (from phonemizer)\n  Downloading segments-2.3.0-py2.py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: attrs>=18.1 in /usr/local/lib/python3.11/dist-packages (from phonemizer) (25.4.0)\nCollecting dlinfo (from phonemizer)\n  Downloading dlinfo-2.0.0-py3-none-any.whl.metadata (1.1 kB)\nCollecting panphon>=0.20 (from epitran)\n  Downloading panphon-0.22.2-py2.py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: marisa-trie in /usr/local/lib/python3.11/dist-packages (from epitran) (1.2.1)\nCollecting jamo (from epitran)\n  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.0) (1.2.0)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy==3.7.4) (1.3.0)\nCollecting unicodecsv (from panphon>=0.20->epitran)\n  Downloading unicodecsv-0.14.1.tar.gz (10 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: editdistance in /usr/local/lib/python3.11/dist-packages (from panphon>=0.20->epitran) (0.8.1)\nCollecting munkres (from panphon>=0.20->epitran)\n  Downloading munkres-1.1.4-py2.py3-none-any.whl.metadata (980 bytes)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from panphon>=0.20->epitran) (2.2.3)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.4) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.4) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.4) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.0) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.0) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.0) (2025.10.5)\nCollecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy==3.7.4)\n  Downloading blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy==3.7.4) (0.1.5)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.11/dist-packages (from typer<0.10.0,>=0.3.0->spacy==3.7.4) (8.3.0)\nCollecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy==3.7.4)\n  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.2) (3.0.3)\nCollecting csvw>=1.5.6 (from segments->phonemizer)\n  Downloading csvw-3.7.0-py2.py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.2) (1.3.0)\nCollecting isodate (from csvw>=1.5.6->segments->phonemizer)\n  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (2.9.0.post0)\nCollecting rfc3986<2 (from csvw>=1.5.6->segments->phonemizer)\n  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: uritemplate>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (4.2.0)\nRequirement already satisfied: babel in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (2.17.0)\nCollecting language-tags (from csvw>=1.5.6->segments->phonemizer)\n  Downloading language_tags-1.2.0-py3-none-any.whl.metadata (2.1 kB)\nCollecting rdflib (from csvw>=1.5.6->segments->phonemizer)\n  Downloading rdflib-7.5.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (3.1.0)\nRequirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from csvw>=1.5.6->segments->phonemizer) (4.25.0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->panphon>=0.20->epitran) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->panphon>=0.20->epitran) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->csvw>=1.5.6->segments->phonemizer) (1.17.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.26.0)\nRequirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from rdflib->csvw>=1.5.6->segments->phonemizer) (3.0.9)\nDownloading transformers-4.41.0-py3-none-any.whl (9.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.1.2-cp311-cp311-manylinux1_x86_64.whl (670.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading spacy-3.7.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\nDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading phonemizer-3.3.0-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.8/103.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading epitran-1.34.0-py3-none-any.whl (222 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m222.4/222.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading panphon-0.22.2-py2.py3-none-any.whl (78 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.9/78.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading thinc-8.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (920 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m920.2/920.2 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading typer-0.9.4-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading weasel-0.3.4-py3-none-any.whl (50 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dlinfo-2.0.0-py3-none-any.whl (3.7 kB)\nDownloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\nDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\nDownloading segments-2.3.0-py2.py3-none-any.whl (15 kB)\nDownloading blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading csvw-3.7.0-py2.py3-none-any.whl (60 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.7/60.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\nDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\nDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\nDownloading language_tags-1.2.0-py3-none-any.whl (213 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m213.4/213.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rdflib-7.5.0-py3-none-any.whl (587 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m587.2/587.2 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: unicodecsv\n  Building wheel for unicodecsv (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for unicodecsv: filename=unicodecsv-0.14.1-py3-none-any.whl size=10744 sha256=3e2dc783f3b3f0323d26075c8a2d5056b9dd42607c86c85deef2d7f5e9ea13a5\n  Stored in directory: /root/.cache/pip/wheels/ec/03/6f/d2e0162d94c0d451556fa43dd4d5531457245c34a36b41ef4a\nSuccessfully built unicodecsv\nInstalling collected packages: unicodecsv, rfc3986, munkres, language-tags, jamo, typer, triton, smart-open, rdflib, portalocker, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, isodate, importlib_metadata, dlinfo, cloudpathlib, blis, sacrebleu, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, tokenizers, panphon, weasel, transformers, thinc, epitran, csvw, spacy, segments, phonemizer\n  Attempting uninstall: typer\n    Found existing installation: typer 0.16.0\n    Uninstalling typer-0.16.0:\n      Successfully uninstalled typer-0.16.0\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: smart-open\n    Found existing installation: smart_open 7.3.0.post1\n    Uninstalling smart_open-7.3.0.post1:\n      Successfully uninstalled smart_open-7.3.0.post1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: importlib_metadata\n    Found existing installation: importlib_metadata 8.7.0\n    Uninstalling importlib_metadata-8.7.0:\n      Successfully uninstalled importlib_metadata-8.7.0\n  Attempting uninstall: cloudpathlib\n    Found existing installation: cloudpathlib 0.21.1\n    Uninstalling cloudpathlib-0.21.1:\n      Successfully uninstalled cloudpathlib-0.21.1\n  Attempting uninstall: blis\n    Found existing installation: blis 1.3.0\n    Uninstalling blis-1.3.0:\n      Successfully uninstalled blis-1.3.0\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: weasel\n    Found existing installation: weasel 0.4.1\n    Uninstalling weasel-0.4.1:\n      Successfully uninstalled weasel-0.4.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.53.3\n    Uninstalling transformers-4.53.3:\n      Successfully uninstalled transformers-4.53.3\n  Attempting uninstall: thinc\n    Found existing installation: thinc 8.3.6\n    Uninstalling thinc-8.3.6:\n      Successfully uninstalled thinc-8.3.6\n  Attempting uninstall: spacy\n    Found existing installation: spacy 3.8.7\n    Uninstalling spacy-3.8.7:\n      Successfully uninstalled spacy-3.8.7\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.1.2 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\ngradio 5.38.1 requires typer<1.0,>=0.12; sys_platform != \"emscripten\", but you have typer 0.9.4 which is incompatible.\ntorchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.1.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed blis-0.7.11 cloudpathlib-0.16.0 csvw-3.7.0 dlinfo-2.0.0 epitran-1.34.0 importlib_metadata-7.1.0 isodate-0.7.2 jamo-0.4.1 language-tags-1.2.0 munkres-1.1.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvtx-cu12-12.1.105 panphon-0.22.2 phonemizer-3.3.0 portalocker-3.2.0 rdflib-7.5.0 rfc3986-1.5.0 sacrebleu-2.5.1 segments-2.3.0 smart-open-6.4.0 spacy-3.7.4 thinc-8.2.5 tokenizers-0.19.1 torch-2.1.2 transformers-4.41.0 triton-2.1.0 typer-0.9.4 unicodecsv-0.14.1 weasel-0.3.4\n\n\u001b[38;5;1mâœ˜ No compatible package found for '-q' (spaCy v3.7.4)\u001b[0m\n\nFound existing installation: torchao 0.10.0\nUninstalling torchao-0.10.0:\n  Successfully uninstalled torchao-0.10.0\nFound existing installation: accelerate 1.9.0\nUninstalling accelerate-1.9.0:\n  Successfully uninstalled accelerate-1.9.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -q sacrebleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T07:25:14.295726Z","iopub.execute_input":"2025-12-30T07:25:14.296900Z","iopub.status.idle":"2025-12-30T07:25:18.250842Z","shell.execute_reply.started":"2025-12-30T07:25:14.296847Z","shell.execute_reply":"2025-12-30T07:25:18.249508Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install -q epitran panphon\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T07:25:18.252268Z","iopub.execute_input":"2025-12-30T07:25:18.252556Z","iopub.status.idle":"2025-12-30T07:25:22.402404Z","shell.execute_reply.started":"2025-12-30T07:25:18.252528Z","shell.execute_reply":"2025-12-30T07:25:22.401135Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# GPT-ONLY","metadata":{}},{"cell_type":"code","source":"# =========================\n# C1: Environment\n# =========================\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n\n# =========================\n# C2: Imports\n# =========================\nimport json\nimport time\nimport random\nfrom typing import List\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\n\nfrom transformers import (\n    GPT2LMHeadModel,\n    GPT2Tokenizer,\n    get_scheduler\n)\n\nfrom sacrebleu import corpus_bleu\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\n# =========================\n# C3: Decoder-only Dataset\n# =========================\nclass DecoderTranslationDataset(Dataset):\n    def __init__(self, data, tokenizer, max_length=128):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        src, tgt = self.data[idx]\n\n        prompt = f\"Source: {src}\\nTarget:\"\n        full_text = f\"{prompt} {tgt}\"\n\n        enc = self.tokenizer(\n            full_text,\n            truncation=True,\n            padding=\"max_length\",\n            max_length=self.max_length,\n            return_tensors=\"pt\"\n        )\n\n        input_ids = enc.input_ids.squeeze()\n        attention_mask = enc.attention_mask.squeeze()\n        labels = input_ids.clone()\n\n        # ğŸ”‘ mask source tokens\n        prompt_len = len(\n            self.tokenizer(prompt, add_special_tokens=False)[\"input_ids\"]\n        )\n        labels[:prompt_len] = -100\n\n        return {\n            \"input_ids\": input_ids,\n            \"attention_mask\": attention_mask,\n            \"labels\": labels,\n            \"target\": tgt\n        }\n\n# =========================\n# C4: Pure Decoder-only GPT\n# =========================\nclass KelantaneseDecoderOnly(nn.Module):\n    def __init__(self, model_name=\"distilgpt2\"):\n        super().__init__()\n\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n        self.tokenizer.pad_token = self.tokenizer.eos_token\n        self.tokenizer.padding_side = \"left\"  # REQUIRED\n\n        self.model = GPT2LMHeadModel.from_pretrained(model_name).to(self.device)\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        return self.model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=labels\n        )\n\n# =========================\n# C5: Load Dataset\n# =========================\njsonl_path = \"/kaggle/input/finaldialectdataset/finalDialect dataset.jsonl\"\n\nall_data = []\nwith open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n    for line in f:\n        obj = json.loads(line.strip())\n        src = obj.get(\"kelantanese\")\n        tgt = obj.get(\"stdMalay\") or obj.get(\"english\")\n        if src and tgt:\n            all_data.append((src, tgt))\n\nrandom.shuffle(all_data)\n\n# ğŸ”½ limit size for speed (optional)\ntrain_data = all_data[:512]\ntest_data  = all_data[512:640]\n\nprint(f\"Train: {len(train_data)} | Test: {len(test_data)}\")\n\n# =========================\n# C6: Dataloader\n# =========================\nmodel = KelantaneseDecoderOnly()\ntokenizer = model.tokenizer\ndevice = model.device\n\ntrain_loader = DataLoader(\n    DecoderTranslationDataset(train_data, tokenizer),\n    batch_size=4,\n    shuffle=True\n)\n\ntest_loader = DataLoader(\n    DecoderTranslationDataset(test_data, tokenizer),\n    batch_size=8\n)\n\n# =========================\n# C7: Optimizer & Scheduler\n# =========================\noptimizer = AdamW(model.parameters(), lr=5e-4)\nepochs = 5\nsteps = len(train_loader) * epochs\n\nscheduler = get_scheduler(\n    \"linear\",\n    optimizer,\n    num_warmup_steps=int(0.1 * steps),\n    num_training_steps=steps\n)\n\n# =========================\n# C8: Training + BLEU\n# =========================\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n    start = time.time()\n\n    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n        batch = {k: v.to(device) for k, v in batch.items() if k != \"target\"}\n\n        out = model(**batch)\n        loss = out.loss\n\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(train_loader)\n\n    # ---------- BLEU ----------\n    model.eval()\n    preds, refs = [], []\n\n    with torch.no_grad():\n        for batch in test_loader:\n            inputs = batch[\"input_ids\"].to(device)\n            masks  = batch[\"attention_mask\"].to(device)\n\n            gen = model.model.generate(\n                input_ids=inputs,\n                attention_mask=masks,\n                max_new_tokens=40,\n                pad_token_id=tokenizer.eos_token_id\n            )\n\n            decoded = tokenizer.batch_decode(gen, skip_special_tokens=True)\n\n            for d, tgt in zip(decoded, batch[\"target\"]):\n                if \"Target:\" in d:\n                    preds.append(d.split(\"Target:\")[-1].strip())\n                    refs.append([tgt])\n\n    bleu = corpus_bleu(preds, refs).score if preds else 0.0\n\n    print(\n        f\"Epoch {epoch+1} | \"\n        f\"Loss {avg_loss:.4f} | \"\n        f\"BLEU {bleu:.2f} | \"\n        f\"Time {time.time()-start:.1f}s\"\n    )\n\n# =========================\n# C9: Sample Predictions\n# =========================\nmodel.eval()\nfor src, tgt in random.sample(test_data, min(5, len(test_data))):\n    prompt = f\"Source: {src}\\nTarget:\"\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n\n    gen = model.model.generate(\n        **inputs,\n        max_new_tokens=40,\n        pad_token_id=tokenizer.eos_token_id\n    )\n\n    out = tokenizer.decode(gen[0], skip_special_tokens=True)\n\n    print(\"SOURCE:\", src)\n    print(\"PRED  :\", out.split(\"Target:\")[-1].strip())\n    print(\"GOLD  :\", tgt)\n    print(\"-\" * 60)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ---VERSION 2 DECODER ONLY","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade accelerate\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Restart Kaggle kernel first\n!pip uninstall -y transformers peft\n!pip install transformers==4.37.0  # stable version\n!pip install datasets sacrebleu torch\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q peft==0.7.1 accelerate==0.25.0\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q \\\n  transformers==4.37.0 \\\n  accelerate==0.26.1 \\\n  peft==0.7.1 \\\n  datasets sacrebleu\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q transformers==4.37.0 accelerate==0.25.0 peft==0.7.1 datasets sacrebleu\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================================================\n# 0ï¸âƒ£ Environment\n# =========================================================\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n# =========================================================\n# 1ï¸âƒ£ Imports\n# =========================================================\nimport json\nimport ast\nimport random\nimport torch\nfrom datasets import Dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForCausalLM,\n    Trainer,\n    TrainingArguments\n)\nfrom sacrebleu.metrics import CHRF\n\n# =========================================================\n# 2ï¸âƒ£ Paths (FOLDERS, not files)\n# =========================================================\nMANGLISH_DIR = \"/kaggle/input/filtered-manglish-1-8kv2\"\nKELANTAN_DIR = \"/kaggle/input/finaldialectdataset\"\n\n# =========================================================\n# 3ï¸âƒ£ Utility: list files safely\n# =========================================================\ndef list_files(folder):\n    files = []\n    for f in os.listdir(folder):\n        path = os.path.join(folder, f)\n        if os.path.isfile(path):\n            files.append(path)\n    return files\n\nmanglish_files = list_files(MANGLISH_DIR)\nkelantan_files = list_files(KELANTAN_DIR)\n\nprint(\"Manglish files:\", manglish_files)\nprint(\"Kelantan files:\", kelantan_files)\n\n# =========================================================\n# 4ï¸âƒ£ Load Kelantanese (proper JSONL)\n# =========================================================\ndef load_kelantanese(files):\n    data = []\n    for path in files:\n        with open(path, \"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                try:\n                    row = json.loads(line)\n                except:\n                    continue\n                if \"kelantanese\" in row and \"stdMalay\" in row:\n                    data.append({\n                        \"dialect\": \"kelantanese\",\n                        \"source\": row[\"kelantanese\"].strip(),\n                        \"target\": row[\"stdMalay\"].strip()\n                    })\n    return data\n\n# =========================================================\n# 5ï¸âƒ£ Load Manglish (LIST-style, broken JSON)\n# =========================================================\ndef load_manglish(files):\n    data = []\n    for path in files:\n        with open(path, \"r\", encoding=\"utf-8\") as f:\n            for line_num, line in enumerate(f, 1):\n                line = line.strip()\n                if not line:\n                    continue\n\n                try:\n                    row = json.loads(line)\n                except:\n                    try:\n                        row = ast.literal_eval(line)\n                    except:\n                        continue\n\n                # Expected:\n                # [\"manglish\", \"text\", {\"malay\": \"...\"}]\n                if (\n                    isinstance(row, list)\n                    and len(row) >= 3\n                    and isinstance(row[2], dict)\n                    and \"malay\" in row[2]\n                ):\n                    data.append({\n                        \"dialect\": \"manglish\",\n                        \"source\": str(row[1]).strip(),\n                        \"target\": row[2][\"malay\"].strip()\n                    })\n    return data\n\n# =========================================================\n# 6ï¸âƒ£ Load + Shuffle Data\n# =========================================================\ndata = load_kelantanese(kelantan_files) + load_manglish(manglish_files)\nrandom.shuffle(data)\n\nprint(f\"âœ… Total samples loaded: {len(data)}\")\n\nassert len(data) > 0, \"âŒ Dataset is EMPTY â€” check file paths!\"\n\n# =========================================================\n# 7ï¸âƒ£ Train / Test Split\n# =========================================================\nsplit = int(0.85 * len(data))\ntrain_data = data[:split]\ntest_data = data[split:]\n\ntrain_ds = Dataset.from_list(train_data)\ntest_ds = Dataset.from_list(test_data)\n\nprint(f\"Train: {len(train_ds)} | Test: {len(test_ds)}\")\n\n# =========================================================\n# 8ï¸âƒ£ GPT-2 Model + Tokenizer\n# =========================================================\nMODEL_NAME = \"gpt2\"\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n\nMAX_LEN = 256\n\n# =========================================================\n# 9ï¸âƒ£ Preprocessing (Causal LM, masked prompt)\n# =========================================================\ndef preprocess(batch):\n    input_ids, labels, attention_mask = [], [], []\n\n    for d, s, t in zip(batch[\"dialect\"], batch[\"source\"], batch[\"target\"]):\n        prompt = (\n            f\"<|dialect|> {d}\\n\"\n            f\"<|source|> {s}\\n\"\n            f\"<|target|> \"\n        )\n\n        full = prompt + t + tokenizer.eos_token\n\n        enc = tokenizer(\n            full,\n            max_length=MAX_LEN,\n            truncation=True,\n            padding=\"max_length\"\n        )\n\n        label = enc[\"input_ids\"].copy()\n        prompt_len = len(tokenizer(prompt)[\"input_ids\"])\n\n        for i in range(prompt_len):\n            label[i] = -100\n\n        input_ids.append(enc[\"input_ids\"])\n        labels.append(label)\n        attention_mask.append(enc[\"attention_mask\"])\n\n    return {\n        \"input_ids\": input_ids,\n        \"labels\": labels,\n        \"attention_mask\": attention_mask\n    }\n\ntrain_ds = train_ds.map(preprocess, batched=True, remove_columns=train_ds.column_names)\ntest_ds = test_ds.map(preprocess, batched=True, remove_columns=test_ds.column_names)\n\ntrain_ds.set_format(\"torch\")\ntest_ds.set_format(\"torch\")\n\n# =========================================================\n# ğŸ”Ÿ Metrics (chrF + exact)\n# =========================================================\nchrf = CHRF()\n\ndef compute_metrics(eval_pred):\n    preds, labels = eval_pred\n    preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    labels = tokenizer.batch_decode(\n        [[l for l in lab if l != -100] for lab in labels],\n        skip_special_tokens=True\n    )\n\n    preds = [p.split(\"<|target|>\")[-1].strip() for p in preds]\n\n    return {\n        \"chrF\": chrf.corpus_score(preds, [labels]).score,\n        \"exact_match\": sum(p == l for p, l in zip(preds, labels)) / len(preds)\n    }\n\n# =========================================================\n# 1ï¸âƒ£1ï¸âƒ£ Training Args (SMALL DATA SAFE)\n# =========================================================\nargs = TrainingArguments(\n    output_dir=\"./gpt_dialect\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=3e-5,\n    num_train_epochs=10,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    gradient_accumulation_steps=8,\n    fp16=torch.cuda.is_available(),\n    logging_steps=50,\n    save_total_limit=2,\n    report_to=\"none\"\n)\n\n# =========================================================\n# 1ï¸âƒ£2ï¸âƒ£ Trainer\n# =========================================================\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=train_ds,\n    eval_dataset=test_ds,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)\n\ntrainer.train()\n\n# =========================================================\n# 1ï¸âƒ£3ï¸âƒ£ Inference\n# =========================================================\ndef translate(text, dialect):\n    prompt = (\n        f\"<|dialect|> {dialect}\\n\"\n        f\"<|source|> {text}\\n\"\n        f\"<|target|> \"\n    )\n    ids = tokenize\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# -----------","metadata":{}},{"cell_type":"markdown","source":"# Shorter Step Version","metadata":{}},{"cell_type":"code","source":"# =========================================================\n# ğŸ”¥ GPT2 DIALECT â†’ MALAY (MANUAL BLEU EVALUATION)\n# Kaggle | ONE CELL | 50 STEPS | STABLE\n# =========================================================\n\n# ---------- 0ï¸âƒ£ INSTALL (SAFE SET) ----------\n!pip uninstall -y transformers accelerate peft -q\n!pip install transformers==4.37.0 accelerate==0.27.2 datasets sacrebleu -q\n\nimport os, json, random, torch\nfrom glob import glob\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\nfrom sacrebleu.metrics import BLEU\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n# ---------- 1ï¸âƒ£ PATHS ----------\nMANGLISH_DIR = \"/kaggle/input/filtered-manglish-1-8kv2\"\nKELANTAN_DIR = \"/kaggle/input/finaldialectdataset\"\n\nmanglish_files = glob(f\"{MANGLISH_DIR}/*.jsonl\")\nkelantan_files = glob(f\"{KELANTAN_DIR}/*.jsonl\")\n\nprint(\"Manglish files:\", manglish_files)\nprint(\"Kelantan files:\", kelantan_files)\n\n# ---------- 2ï¸âƒ£ SAFE LOADERS ----------\ndef safe_jsonl(path):\n    rows = []\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        for line in f:\n            try:\n                rows.append(json.loads(line.strip()))\n            except:\n                continue\n    return rows\n\ndef load_kelantan(files):\n    out = []\n    for f in files:\n        for r in safe_jsonl(f):\n            if \"kelantanese\" in r and \"stdMalay\" in r:\n                out.append({\n                    \"dialect\": \"kelantanese\",\n                    \"source\": r[\"kelantanese\"],\n                    \"target\": r[\"stdMalay\"]\n                })\n    return out\n\ndef load_manglish(files):\n    out = []\n    for f in files:\n        for r in safe_jsonl(f):\n            if \"text\" in r and \"malay\" in r:\n                out.append({\n                    \"dialect\": \"manglish\",\n                    \"source\": r[\"text\"],\n                    \"target\": r[\"malay\"]\n                })\n    return out\n\ndata = load_kelantan(kelantan_files) + load_manglish(manglish_files)\nrandom.shuffle(data)\n\nprint(f\"âœ… Total samples loaded: {len(data)}\")\n\n# ---------- 3ï¸âƒ£ SPLIT ----------\nsplit = int(0.85 * len(data))\ntrain_data = data[:split]\neval_data  = data[split:]\n\ntrain_ds = Dataset.from_list(train_data)\neval_ds  = Dataset.from_list(eval_data)\n\nprint(f\"Train: {len(train_ds)} | Eval: {len(eval_ds)}\")\n\n# ---------- 4ï¸âƒ£ MODEL ----------\nMODEL = \"gpt2\"\ntokenizer = AutoTokenizer.from_pretrained(MODEL)\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel = AutoModelForCausalLM.from_pretrained(MODEL)\n\nMAX_LEN = 256\n\n# ---------- 5ï¸âƒ£ TOKENIZE ----------\ndef preprocess(batch):\n    input_ids, labels, masks = [], [], []\n\n    for d, s, t in zip(batch[\"dialect\"], batch[\"source\"], batch[\"target\"]):\n        prompt = f\"<|dialect|> {d}\\n<|source|> {s}\\n<|target|> \"\n        full = prompt + t + tokenizer.eos_token\n\n        enc = tokenizer(full, truncation=True, padding=\"max_length\", max_length=MAX_LEN)\n        lab = enc[\"input_ids\"].copy()\n\n        p_len = len(tokenizer(prompt)[\"input_ids\"])\n        lab[:p_len] = [-100] * p_len\n\n        input_ids.append(enc[\"input_ids\"])\n        labels.append(lab)\n        masks.append(enc[\"attention_mask\"])\n\n    return {\n        \"input_ids\": input_ids,\n        \"labels\": labels,\n        \"attention_mask\": masks\n    }\n\ntrain_ds = train_ds.map(preprocess, batched=True, remove_columns=train_ds.column_names)\neval_ds  = eval_ds.map(preprocess, batched=True, remove_columns=eval_ds.column_names)\n\ntrain_ds.set_format(\"torch\")\neval_ds.set_format(\"torch\")\n\n# ---------- 6ï¸âƒ£ TRAIN ----------\nargs = TrainingArguments(\n    output_dir=\"./gpt2-dialect\",\n    max_steps=50,                  # ğŸ”¥ ONLY 50 STEPS\n    per_device_train_batch_size=2,\n    gradient_accumulation_steps=4,\n    learning_rate=5e-5,\n    logging_steps=5,\n    save_steps=50,\n    evaluation_strategy=\"no\",      # âš  GPT Trainer = loss only\n    report_to=\"none\",\n    fp16=torch.cuda.is_available()\n)\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=train_ds,\n    tokenizer=tokenizer\n)\n\ntrainer.train()\n\n# =========================================================\n# 7ï¸âƒ£ MANUAL BLEU EVALUATION (CORRECT WAY FOR GPT)\n# =========================================================\n\nbleu = BLEU()\n\ndef generate(text, dialect):\n    prompt = f\"<|dialect|> {dialect}\\n<|source|> {text}\\n<|target|> \"\n    ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n    out = model.generate(ids, max_new_tokens=60)\n    return tokenizer.decode(out[0], skip_special_tokens=True).split(\"<|target|>\")[-1].strip()\n\npreds, refs = [], []\n\nfor ex in eval_data[:100]:   # ğŸ”¥ evaluate first 100 samples (fast)\n    pred = generate(ex[\"source\"], ex[\"dialect\"])\n    preds.append(pred)\n    refs.append(ex[\"target\"])\n\nbleu_score = bleu.corpus_score(preds, [refs]).score\n\nprint(\"\\nâœ… BLEU SCORE:\")\nprint(f\"BLEU = {bleu_score:.2f}\")\n\n# ---------- 8ï¸âƒ£ DEMO ----------\nprint(\"\\nKelantanese â†’ Malay:\")\nprint(generate(\"Nasi ni sedho sikit\", \"kelantanese\"))\n\nprint(\"\\nManglish â†’ Malay:\")\nprint(generate(\"aiyo dont do like that lah\", \"manglish\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T08:01:53.344942Z","iopub.execute_input":"2025-12-30T08:01:53.345580Z","iopub.status.idle":"2025-12-30T08:17:03.913145Z","shell.execute_reply.started":"2025-12-30T08:01:53.345549Z","shell.execute_reply":"2025-12-30T08:17:03.912177Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping peft as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mManglish files: ['/kaggle/input/filtered-manglish-1-8kv2/filtered-manglish_1.8k .jsonl']\nKelantan files: ['/kaggle/input/finaldialectdataset/finalDialect dataset.jsonl']\nâœ… Total samples loaded: 1886\nTrain: 1603 | Eval: 283\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1603 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0425213cbaa74b23b02dcdd05f83fd37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/283 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc90f485e478479eb5bfa56c20b0a2ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 13:53, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>5</td>\n      <td>4.772900</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.178000</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.129100</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.101900</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.104000</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.131600</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.092800</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.109500</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.126900</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.130200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nâœ… BLEU SCORE:\nBLEU = 10.26\n\nKelantanese â†’ Malay:\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"ikatakatat\n\nManglish â†’ Malay:\nikunu kunu kunu kunu kunu kunu kunu kunu kunu kunu kunu kunu kunu kunu kunu kunu kunu kunu kunu kunu\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}